{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts de pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, RobustScaler, MaxAbsScaler, PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_balancing(X: pd.DataFrame, y: pd.Series, tomek: str='majority', smote: str='not majority') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retorna um DataFrame com as classes balanceadas das seguinte forma:\n",
    "    1. Reduz a classe majoritária usando liagacoes de TOMEK (remover instancias que nao adicionam muita informacao).\n",
    "    2. Equaliza as demais classes usando SMOTE para ficarem com a mesma quantidade de instancias que a classe majoritaria.\n",
    "\n",
    "    :param X: DataFrame com as variaveis independentes\n",
    "    :X type: pd.DataFrame\n",
    "    :param y: Series com a variavel dependente\n",
    "    :y type: pd.Series\n",
    "    :param tomek: tipo de undersampling a ser feito pelo TOMEK\n",
    "    :tomek type: str\n",
    "    :param smote: tipo de oversampling a ser feito pelo SMOTE\n",
    "    :smote type: str\n",
    "    :return: DataFrame transformado\n",
    "    :rtype: pd.Dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    tl = TomekLinks(sampling_strategy=tomek)\n",
    "    X_tl, y_tl = tl.fit_resample(X, y)\n",
    "\n",
    "    sm = SMOTE(sampling_strategy=smote)\n",
    "    X_tl_sm, y_tl_sm = sm.fit_resample(X_tl, y_tl)\n",
    "\n",
    "    df_tl_sm = pd.concat([X_tl_sm, y_tl_sm], axis=1)\n",
    "    \n",
    "    return df_tl_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(num_vars: pd.DataFrame, scaler: str='minmax') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    metodo que detecta qual o melhor scaler a ser usado.\n",
    "\n",
    "    :param df: DataFrame alvo das transformacoes\n",
    "    :df type: pd.DataFrame\n",
    "    :param cols: Lista de colunas que devem ser transformadas\n",
    "    :cols type: list\n",
    "    :return: DataFrame transformado\n",
    "    :rtype: pd.Dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    if scaler == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scaler == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler == 'normalizer':\n",
    "        scaler = Normalizer()\n",
    "    elif scaler == 'robust':\n",
    "        scaler = RobustScaler()\n",
    "    else:\n",
    "        raise ValueError(f\"Scaler '{scaler}' não é reconhecido. Use 'minmax', 'standard', 'normalizer', ou 'robust'.\")\n",
    "    \n",
    "    return pd.DataFrame(scaler.fit_transform(num_vars), columns=num_vars.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(cat_vars: pd.DataFrame, cat_cols: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Executa o One Hot Encoding em cada coluna fornecida de um DataFrame.\n",
    "\n",
    "    :param df: DataFrame alvo das transformacoes\n",
    "    :df type: pd.DataFrame\n",
    "    :param cols: Lista de colunas que devem ser transformadas\n",
    "    :cols type: list\n",
    "    :return: DataFrame transformado\n",
    "    :rtype: pd.Dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "    return pd.DataFrame(one_hot_encoder.fit_transform(cat_vars), columns=one_hot_encoder.get_feature_names_out(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cols(df: pd.DataFrame, cols: list) -> pd.DataFrame:\n",
    "    return df.drop(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame, num_cols: list, cat_cols: list, scaler='minmax') -> pd.DataFrame:\n",
    "    #df = remove_cols()\n",
    "    \n",
    "    X = df.drop(columns=['Target'])\n",
    "    y = df['Target']\n",
    "\n",
    "    df = hybrid_balancing(X, y)\n",
    "\n",
    "    num_vars = df[num_cols]\n",
    "    cat_vars = df[cat_cols]\n",
    "    \n",
    "    num_vars_scaled = scaling(num_vars, scaler)\n",
    "\n",
    "    cat_vars_encoded = one_hot_encoding(cat_vars, cat_cols)\n",
    "\n",
    "    df_balanced_scaled_encoded = pd.concat([num_vars_scaled, cat_vars_encoded], axis=1)\n",
    "\n",
    "    return df_balanced_scaled_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/students.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "    'Marital status', \n",
    "    'Application mode', \n",
    "    'Course',\n",
    "    'Daytime/evening attendance', \n",
    "    'Previous qualification', \n",
    "    'Nacionality',\n",
    "    'Mother\\'s qualification', \n",
    "    'Father\\'s qualification',\n",
    "    'Mother\\'s occupation', \n",
    "    'Father\\'s occupation', \n",
    "    'Displaced',\n",
    "    'Educational special needs', \n",
    "    'Debtor', \n",
    "    'Tuition fees up to date',\n",
    "    'Gender', \n",
    "    'Scholarship holder', \n",
    "    'International',\n",
    "    'Application order'\n",
    "    ]            \n",
    "\n",
    "num_cols = [\n",
    "    'Age at enrollment',\n",
    "    'Curricular units 1st sem (credited)',\n",
    "    'Curricular units 1st sem (enrolled)',\n",
    "    'Curricular units 1st sem (evaluations)',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (grade)',\n",
    "    'Curricular units 1st sem (without evaluations)',\n",
    "    'Curricular units 2nd sem (credited)',\n",
    "    'Curricular units 2nd sem (enrolled)',\n",
    "    'Curricular units 2nd sem (evaluations)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)',\n",
    "    'Curricular units 2nd sem (without evaluations)',\n",
    "    'Unemployment rate',\n",
    "    'Inflation rate', \n",
    "    'GDP'\n",
    "]\n",
    "\n",
    "cat_dropped_nonbinary_cols = [\n",
    "    'Marital status', \n",
    "    'Application mode', \n",
    "    'Course',\n",
    "    'Previous qualification',\n",
    "    'Mother\\'s qualification', \n",
    "    'Father\\'s qualification',\n",
    "    'Mother\\'s occupation', \n",
    "    'Father\\'s occupation', \n",
    "    'Application order']\n",
    "\n",
    "cat_dropped_binary_cols = [\n",
    "    'Daytime/evening attendance', \n",
    "    'Displaced',\n",
    "    'Debtor', \n",
    "    'Tuition fees up to date',\n",
    "    'Gender', \n",
    "    'Scholarship holder',\n",
    "    'Target'\n",
    "]\n",
    "\n",
    "cat_dropped_cols = [\n",
    "    'Age at enrollment',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Unemployment rate',\n",
    "    'Inflation rate', \n",
    "    'GDP'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marital status                                      6\n",
       "Application mode                                   18\n",
       "Application order                                   8\n",
       "Course                                             17\n",
       "Daytime/evening attendance                          2\n",
       "Previous qualification                             17\n",
       "Nacionality                                        21\n",
       "Mother's qualification                             29\n",
       "Father's qualification                             34\n",
       "Mother's occupation                                32\n",
       "Father's occupation                                46\n",
       "Displaced                                           2\n",
       "Educational special needs                           2\n",
       "Debtor                                              2\n",
       "Tuition fees up to date                             2\n",
       "Gender                                              2\n",
       "Scholarship holder                                  2\n",
       "Age at enrollment                                  46\n",
       "International                                       2\n",
       "Curricular units 1st sem (credited)                21\n",
       "Curricular units 1st sem (enrolled)                23\n",
       "Curricular units 1st sem (evaluations)             35\n",
       "Curricular units 1st sem (approved)                23\n",
       "Curricular units 1st sem (grade)                  805\n",
       "Curricular units 1st sem (without evaluations)     11\n",
       "Curricular units 2nd sem (credited)                19\n",
       "Curricular units 2nd sem (enrolled)                22\n",
       "Curricular units 2nd sem (evaluations)             30\n",
       "Curricular units 2nd sem (approved)                20\n",
       "Curricular units 2nd sem (grade)                  786\n",
       "Curricular units 2nd sem (without evaluations)     10\n",
       "Unemployment rate                                  10\n",
       "Inflation rate                                      9\n",
       "GDP                                                10\n",
       "Target                                              3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_preprocessed = preprocess_data(df, num_cols, cat_cols)\n",
    "df_full_preprocessed.to_csv('../data/students_TargetOHC.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OHE_scaled = df.copy()\n",
    "\n",
    "num_vars = df[cat_dropped_cols]\n",
    "cat_vars = df[cat_dropped_nonbinary_cols]\n",
    "bin_var = df[cat_dropped_binary_cols]\n",
    "\n",
    "num_vars_scaled = scaling(num_vars, 'minmax')\n",
    "\n",
    "cat_vars_encoded = one_hot_encoding(cat_vars, cat_dropped_nonbinary_cols)\n",
    "\n",
    "df_OHE_scaled = pd.concat([num_vars_scaled, bin_var, cat_vars_encoded], axis=1)\n",
    "df_OHE_scaled.to_csv('../data/OHE_scaled_target.csv', index=False)\n",
    "\n",
    "df_scaled = pd.concat([num_vars, bin_var, cat_vars], axis=1)\n",
    "df_scaled.to_csv('../data/scaled_target.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
